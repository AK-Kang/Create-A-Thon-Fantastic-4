{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homelessness Prediction Project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyaa06/Create-A-Thon-Fantastic-4/blob/main/Homelessness_Prediction_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to data source (also has the link to the data dictionary)  https://www.huduser.gov/portal/datasets//hpmd.html"
      ],
      "metadata": {
        "id": "r-8Ay_jcfxKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc-Fx2ahfVAG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"https://www.huduser.gov/portal/sites/default/files/xls/05b_analysis_file_update.csv\")"
      ],
      "metadata": {
        "id": "CMtsmcn_fdmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FUNCTIONS"
      ],
      "metadata": {
        "id": "vBSbf5UcXRD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(outcome_var):\n",
        "\n",
        "  # CREATE LISTS FOR OUTCOME VARIABLES\n",
        "  outcomes = list(dataset.keys())[2:5] + [\"pit_miss\", \n",
        "                                        \"odd_flag\", \n",
        "                                        \"pit_hless_balance\", \n",
        "                                        \"pit_shelt_balance\", \n",
        "                                        \"pit_unshelt_balance\", \n",
        "                                        \"unbalance_flag\", \n",
        "                                        \"pit_shelt_pit_hud_share\", \n",
        "                                        \"pit_unshelt_pit_hud_share\",\n",
        "                                        \"pit_hless_pit_hud_share\",\n",
        "                                        \"missing\"]\n",
        "                                        \n",
        "  secondary_outcomes = list(dataset.keys())[5:14] + list(dataset.keys())[17:22]\n",
        "\n",
        "  # ISOLATE TRAINING FEATURES FROM TOTAL DATASET\n",
        "  features_df = dataset.drop([\"year\", \"cocnumber\", \"coctag\", \"panelvar\", \"state_abr\"] + outcomes + secondary_outcomes, axis=1, inplace=False)\n",
        "\n",
        "  # CREATE DATAFRAME OF ALL OUTCOME VARIABLE DATA\n",
        "  possible_outcomes_df = dataset[outcomes + secondary_outcomes]\n",
        "\n",
        "  # IDENTIFY (AND DROP) FEATURES WITH MANY NAN VALUES\n",
        "  NaN_features = []\n",
        "\n",
        "  for key in features_df.keys():\n",
        "    if features_df[key].isna().sum() > 300:\n",
        "      NaN_features.append(key)\n",
        "\n",
        "  features_df.drop(NaN_features, axis=1, inplace=True)\n",
        "\n",
        "  # FILL IN THE FEW REMAINING NAN VALUES WITH COLUMN-WISE AVERAGE\n",
        "  for key in features_df.keys():\n",
        "    # print(key)\n",
        "    features_df[key].fillna(value=round(features_df[key].mean()), inplace=True)\n",
        "\n",
        "  # ADDING OUTCOME VAR TO THE END OF THE DATASET\n",
        "  features_df[outcome_var] = possible_outcomes_df[outcome_var]\n",
        "\n",
        "  # DROP THE NAN VALUES THAT ARE PRESENT IN THE OUTCOME VAR\n",
        "  final_df = features_df.dropna()\n",
        "\n",
        "  return final_df\n"
      ],
      "metadata": {
        "id": "tq8h81OpPruK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_data(data):\n",
        "\n",
        "  X = data.iloc[:, :-1].values\n",
        "  y = data.iloc[:, -1].values\n",
        "  #I just wrote this assuming we're using the last variable for the predicted variable but we can change it accordingly\n",
        "\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 6)\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  sc = StandardScaler()\n",
        "  X_train = sc.fit_transform(X_train)\n",
        "  X_test = sc.transform(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "o-eBfYesdFuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for training and testing different models\n",
        "\n",
        "def train_and_test_func(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  from sklearn.linear_model import LinearRegression, ElasticNet, Ridge, Lasso, BayesianRidge\n",
        "\n",
        "  print(\"Model:\".ljust(20), \"R2 Score:\")\n",
        "  print()\n",
        "\n",
        "  lr = LinearRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  print(\"Linear Regression:\".ljust(20), lr.score(X_test, y_test))\n",
        "\n",
        "  en = ElasticNet()\n",
        "  en.fit(X_train, y_train)\n",
        "  print(\"ElasticNet:\".ljust(20), en.score(X_test, y_test))\n",
        "\n",
        "  rd = Ridge()\n",
        "  rd.fit(X_train, y_train)\n",
        "  print(\"Ridge:\".ljust(20), rd.score(X_test, y_test))\n",
        "\n",
        "  ls = Lasso()\n",
        "  ls.fit(X_train, y_train)\n",
        "  print(\"Lasso:\".ljust(20), ls.score(X_test, y_test))\n",
        "\n",
        "  br = BayesianRidge()\n",
        "  br.fit(X_train, y_train)\n",
        "  print(\"Bayesian Ridge:\".ljust(20), br.score(X_test, y_test))\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "id": "dGkYTdyYMcRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL EXPERIMENTATION"
      ],
      "metadata": {
        "id": "s90ZdhYVXfY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PRINT NAN COUNT FOR EACH OF THE POSSIBLE OUTCOME VARIABLES\n",
        "\n",
        "outcomes = list(dataset.keys())[2:5] + [\"pit_miss\", \n",
        "                                      \"odd_flag\", \n",
        "                                      \"pit_hless_balance\", \n",
        "                                      \"pit_shelt_balance\", \n",
        "                                      \"pit_unshelt_balance\", \n",
        "                                      \"unbalance_flag\", \n",
        "                                      \"pit_shelt_pit_hud_share\", \n",
        "                                      \"pit_unshelt_pit_hud_share\",\n",
        "                                      \"pit_hless_pit_hud_share\",\n",
        "                                      \"missing\"]\n",
        "                                      \n",
        "secondary_outcomes = list(dataset.keys())[5:14] + list(dataset.keys())[17:22]\n",
        "\n",
        "possible_outcomes_df = dataset[outcomes + secondary_outcomes]\n",
        "\n",
        "#--\n",
        "print(\"Key:\".ljust(35), \"NaN Count\")\n",
        "print()\n",
        "\n",
        "for key in possible_outcomes_df.keys():\n",
        "  print(key.ljust(35), possible_outcomes_df[key].isna().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_0y-I4BDR5R",
        "outputId": "3280a821-e09e-4960-ccea-727baf053b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key:                                NaN Count\n",
            "\n",
            "pit_tot_shelt_pit_hud               14\n",
            "pit_tot_unshelt_pit_hud             14\n",
            "pit_tot_hless_pit_hud               14\n",
            "pit_miss                            0\n",
            "odd_flag                            0\n",
            "pit_hless_balance                   0\n",
            "pit_shelt_balance                   0\n",
            "pit_unshelt_balance                 0\n",
            "unbalance_flag                      0\n",
            "pit_shelt_pit_hud_share             14\n",
            "pit_unshelt_pit_hud_share           14\n",
            "pit_hless_pit_hud_share             14\n",
            "missing                             0\n",
            "pit_ind_shelt_pit_hud               14\n",
            "pit_ind_unshelt_pit_hud             14\n",
            "pit_ind_hless_pit_hud               14\n",
            "pit_perfam_shelt_pit_hud            14\n",
            "pit_perfam_unshelt_pit_hud          14\n",
            "pit_perfam_hless_pit_hud            14\n",
            "pit_ind_chronic_hless_pit_hud       14\n",
            "pit_perfam_chronic_hless_pit_hud    1137\n",
            "pit_vet_hless_pit_hud               387\n",
            "hou_pol_totalind_hud                2259\n",
            "hou_pol_totalday_hud                2259\n",
            "hou_pol_totalexit_hud               2259\n",
            "hou_pol_numret6mos_hud              2259\n",
            "hou_pol_numret12mos_hud             2259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATE DATA BASED ON OUTCOME VARIABLE\n",
        "DATA = generate_data(outcome_var = \"pit_ind_chronic_hless_pit_hud\") # ths outcome variable can be adjusted to whatever we want"
      ],
      "metadata": {
        "id": "PKuO6-D0SQwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test_data(DATA)"
      ],
      "metadata": {
        "id": "QjefP3DuW8FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_func(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGOhs3N3NlAh",
        "outputId": "cd0d83e6-9202-4db1-e00d-287478f24e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model:               R2 Score:\n",
            "\n",
            "Linear Regression:   0.8288487927438104\n",
            "ElasticNet:          0.7354505066786698\n",
            "Ridge:               0.8206148114592273\n",
            "Lasso:               0.8192637107304898\n",
            "Bayesian Ridge:      0.8188413218809069\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Graveyard"
      ],
      "metadata": {
        "id": "nIOyY4sZTWlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# options for our predicted variables\n",
        "outcomes = list(dataset.keys())[2:5] + [\"pit_miss\", \n",
        "                                        \"odd_flag\", \n",
        "                                        \"pit_hless_balance\", \n",
        "                                        \"pit_shelt_balance\", \n",
        "                                        \"pit_unshelt_balance\", \n",
        "                                        \"unbalance_flag\", \n",
        "                                        \"pit_shelt_pit_hud_share\", \n",
        "                                        \"pit_unshelt_pit_hud_share\",\n",
        "                                        \"pit_hless_pit_hud_share\",\n",
        "                                        \"missing\"]\n",
        "                                        \n",
        "secondary_outcomes = list(dataset.keys())[5:14] + list(dataset.keys())[17:22]\n",
        "print(outcomes)\n",
        "print(secondary_outcomes)"
      ],
      "metadata": {
        "id": "EQJqhHCGflrk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5182bf6-385a-47c9-b064-4767f4e86e8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pit_tot_shelt_pit_hud', 'pit_tot_unshelt_pit_hud', 'pit_tot_hless_pit_hud', 'pit_miss', 'odd_flag', 'pit_hless_balance', 'pit_shelt_balance', 'pit_unshelt_balance', 'unbalance_flag', 'pit_shelt_pit_hud_share', 'pit_unshelt_pit_hud_share', 'pit_hless_pit_hud_share', 'missing']\n",
            "['pit_ind_shelt_pit_hud', 'pit_ind_unshelt_pit_hud', 'pit_ind_hless_pit_hud', 'pit_perfam_shelt_pit_hud', 'pit_perfam_unshelt_pit_hud', 'pit_perfam_hless_pit_hud', 'pit_ind_chronic_hless_pit_hud', 'pit_perfam_chronic_hless_pit_hud', 'pit_vet_hless_pit_hud', 'hou_pol_totalind_hud', 'hou_pol_totalday_hud', 'hou_pol_totalexit_hud', 'hou_pol_numret6mos_hud', 'hou_pol_numret12mos_hud']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "possible_outcomes_df = dataset[outcomes + secondary_outcomes]"
      ],
      "metadata": {
        "id": "EQ9lPtrtW4SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# isolate training feaures (dropping identifiers and outcome columns)\n",
        "features_df = dataset.drop([\"year\", \"cocnumber\", \"coctag\", \"panelvar\", \"state_abr\"] + outcomes + secondary_outcomes, axis=1, inplace=False)"
      ],
      "metadata": {
        "id": "qNovZ6RaSn6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying features with lots of NaN(missing) values\n",
        "NaN_features = []\n",
        "\n",
        "for key in features_df.keys():\n",
        "  if features_df[key].isna().sum() > 300:\n",
        "    NaN_features.append(key)\n",
        "  # print(key.ljust(35), features_df[key].isna().sum())"
      ],
      "metadata": {
        "id": "rouxePB-e3sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the Nan features\n",
        "features_df.drop(NaN_features, axis=1, inplace=True)\n",
        "# features_df"
      ],
      "metadata": {
        "id": "auf6O9e6sDQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling the remaining NaNs with the mean of the column\n",
        "for key in features_df.keys():\n",
        "  # print(key)\n",
        "  features_df[key].fillna(value=round(features_df[key].mean()), inplace=True)"
      ],
      "metadata": {
        "id": "0GFkDIKhALyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding our outcome var to the end of the dataset\n",
        "features_df[outcome_var] = possible_outcomes_df[outcome_var]\n",
        "# features_df"
      ],
      "metadata": {
        "id": "n_8jOGrBFZOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome_var = \"pit_tot_shelt_pit_hud\""
      ],
      "metadata": {
        "id": "ob9mEUb-FUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 14 (or however many) NaN values are present in the outcome var\n",
        "dataset = features_df.dropna()"
      ],
      "metadata": {
        "id": "wFmpcIN-F1bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'VE COMMENTED THIS OUT FOR NOW BECAUSE 0 COLUMNS WERE LABEL ENCODED\n",
        "# (still keeping the code in case we need it later)\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# le_count = 0\n",
        "# for col in DATA.columns[1:]:\n",
        "#     if DATA[col].dtype == 'object':\n",
        "#         if len(list(DATA[col].unique())) <= 2:\n",
        "#             le.fit(DATA[col])\n",
        "#             DATA[col] = le.transform(DATA[col])\n",
        "#             le_count += 1\n",
        "# print('{} columns were label encoded.'.format(le_count))"
      ],
      "metadata": {
        "id": "5EMyqrKUfmX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d531cdd-fc83-43a5-bacf-2b49525f417a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 columns were label encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I'VE COMMENTED THIS OUT FOR NOW BECAUSE 0 COLUMNS WERE ONE-HOT ENCODED\n",
        "# (still keeping the code in case we need it later)\n",
        "\n",
        "# from sklearn.compose import ColumnTransformer\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# ct_count = 0\n",
        "# for col in DATA.columns[1:]:\n",
        "#     if DATA[col].dtype == 'object':\n",
        "#         if len(list(DATA[col].unique())) >= 2:\n",
        "#           DATA = pd.concat([DATA,pd.get_dummies(DATA[col], prefix=col)], axis=1)\n",
        "#           DATA.drop([col],axis=1, inplace=True)\n",
        "#           ct_count += 1\n",
        "# print('{} columns were one-hot encoded.'.format(ct_count))\n"
      ],
      "metadata": {
        "id": "5rmv2-uHdFGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e85340-92ff-41f1-fa7a-f59c2b7f33b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 columns were one-hot encoded.\n"
          ]
        }
      ]
    }
  ]
}